package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"

	"github.com/IBM/sarama"
)

type KafkaClient struct {
	brokers  []string
	username string
	password string
	config   *sarama.Config
}

type ConsumerGroupHandler struct {
	name string
}

// Setup åœ¨æ¶ˆè´¹è€…ç»„ä¼šè¯å¼€å§‹æ—¶è°ƒç”¨
func (h ConsumerGroupHandler) Setup(sarama.ConsumerGroupSession) error {
	log.Printf("ğŸŸ¢ [%s] æ¶ˆè´¹è€…ç»„ä¼šè¯å¼€å§‹\n", h.name)
	return nil
}

// Cleanup åœ¨æ¶ˆè´¹è€…ç»„ä¼šè¯ç»“æŸæ—¶è°ƒç”¨
func (h ConsumerGroupHandler) Cleanup(sarama.ConsumerGroupSession) error {
	log.Printf("ğŸ”´ [%s] æ¶ˆè´¹è€…ç»„ä¼šè¯ç»“æŸ\n", h.name)
	return nil
}

// ConsumeClaim å¤„ç†æ¶ˆæ¯
func (h ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for {
		select {
		case message := <-claim.Messages():
			if message == nil {
				return nil
			}

			log.Printf("ğŸ“¨ [%s] æ”¶åˆ°æ¶ˆæ¯:\n", h.name)
			log.Printf("   â”œâ”€ Topic: %s\n", message.Topic)
			log.Printf("   â”œâ”€ Partition: %d\n", message.Partition)
			log.Printf("   â”œâ”€ Offset: %d\n", message.Offset)
			log.Printf("   â”œâ”€ Key: %s\n", string(message.Key))
			log.Printf("   â”œâ”€ Value: %s\n", string(message.Value))
			log.Printf("   â”œâ”€ Timestamp: %s\n", message.Timestamp.Format("2025-11-02 15:04:05"))
			log.Printf("   â””â”€ Headers: %v\n", message.Headers)

			// æ ‡è®°æ¶ˆæ¯å·²å¤„ç†
			session.MarkMessage(message, "")

		case <-session.Context().Done():
			return nil
		}
	}
}

func (kc *KafkaClient) ListAllTopics() error {
	client, err := sarama.NewClient(kc.brokers, kc.config)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}
	defer client.Close()

	topics, err := client.Topics()
	if err != nil {
		return fmt.Errorf("è·å– topics å¤±è´¥: %w", err)
	}

	log.Printf("\n========== Kafka é›†ç¾¤æ‰€æœ‰ Topic ==========\n")
	for _, topic := range topics {
		partitions, _ := client.Partitions(topic)
		totalMessages := int64(0)
		for _, p := range partitions {
			oldest, _ := client.GetOffset(topic, p, sarama.OffsetOldest)
			newest, _ := client.GetOffset(topic, p, sarama.OffsetNewest)
			totalMessages += newest - oldest
		}
		log.Printf("Topic: %s | Partitions: %d | æ¶ˆæ¯æ€»æ•°: %d\n", topic, len(partitions), totalMessages)
	}
	log.Println("==========================================")
	return nil
}

// æ„é€ å‡½æ•° åˆ›å»ºå¯¹è±¡
func NewKafkaClient(broker []string, username, password string) *KafkaClient {
	cfg := sarama.NewConfig()
	cfg.Version = sarama.V4_0_0_0
	if username != "" {
		cfg.Net.SASL.Enable = true
		cfg.Net.SASL.User = username
		cfg.Net.SASL.Password = password
		cfg.Net.SASL.Mechanism = sarama.SASLTypePlaintext
	}
	return &KafkaClient{broker, username, password, cfg}
}

// åˆ›å»ºç”Ÿäº§è€…
func (kc *KafkaClient) NewProducer() (sarama.SyncProducer, error) {
	cfg := kc.config
	cfg.Producer.Return.Successes = true
	cfg.Producer.RequiredAcks = sarama.WaitForAll
	cfg.Producer.Idempotent = true
	cfg.Producer.Retry.Max = 10
	cfg.Producer.Compression = sarama.CompressionSnappy
	cfg.Net.MaxOpenRequests = 1
	return sarama.NewSyncProducer(kc.brokers, cfg)
}

func (kc *KafkaClient) SendMessage(producer sarama.SyncProducer, topic, key, value string) error {
	msg := &sarama.ProducerMessage{
		Topic: topic,
		Key:   sarama.StringEncoder(key),
		Value: sarama.StringEncoder(value),
	}
	partition, offset, err := producer.SendMessage(msg)
	if err != nil {
		return err
	}
	log.Printf("Message sent to partition %d at offset %d\n", partition, offset)
	return nil
}

func (kc *KafkaClient) GetTopicInfo(topic string) error {
	client, err := sarama.NewClient(kc.brokers, kc.config)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥:%w", err)
	}
	defer client.Close()
	partitions, err := client.Partitions(topic)
	if err != nil {
		return fmt.Errorf("è·å–åˆ†åŒºå¤±è´¥: %w", err)
	}

	log.Printf("\n========== Topic '%s' ä¿¡æ¯ ==========\n", topic)
	totalMessages := int64(0)

	for _, partition := range partitions {
		oldest, _ := client.GetOffset(topic, partition, sarama.OffsetOldest)
		newest, _ := client.GetOffset(topic, partition, sarama.OffsetNewest)
		count := newest - oldest
		totalMessages += count

		log.Printf("Partition %d: %d æ¡æ¶ˆæ¯ (offset: %d -> %d)\n", partition, count, oldest, newest-1)
	}

	log.Printf("æ€»è®¡: %d æ¡æ¶ˆæ¯\n", totalMessages)
	log.Println("======================================")
	return nil
}

func (kc *KafkaClient) NewConsumerGroup(groupID string) (sarama.ConsumerGroup, error) {
	cfg := kc.config
	cfg.Consumer.Group.Rebalance.Strategy = sarama.NewBalanceStrategyRoundRobin()
	cfg.Consumer.Offsets.Initial = sarama.OffsetOldest
	cfg.Consumer.Return.Errors = true

	return sarama.NewConsumerGroup(kc.brokers, groupID, cfg)
}

func (kc *KafkaClient) StartConsumerGroup(groupID string, topics []string, ctx context.Context) error {
	consumerGroup, err := kc.NewConsumerGroup(groupID)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤±è´¥: %w", err)
	}
	defer consumerGroup.Close()

	handler := ConsumerGroupHandler{name: groupID}

	log.Printf("[%s] æ¶ˆè´¹è€…ç»„å¯åŠ¨ï¼Œè®¢é˜… topics: %v\n", groupID, topics)

	// å¤„ç†é”™è¯¯
	go func() {
		for err := range consumerGroup.Errors() {
			log.Printf("[%s] æ¶ˆè´¹è€…ç»„é”™è¯¯: %v\n", groupID, err)
		}
	}()

	// æŒç»­æ¶ˆè´¹
	for {
		select {
		case <-ctx.Done():
			log.Printf("[%s] æ¶ˆè´¹è€…ç»„åœæ­¢\n", groupID)
			return nil
		default:
			if err := consumerGroup.Consume(ctx, topics, handler); err != nil {
				log.Printf("[%s] æ¶ˆè´¹å¤±è´¥: %v\n", groupID, err)
				return err
			}
		}
	}
}

func (kc *KafkaClient) StartConsumerGroupAsync(groupID string, topics []string, ctx context.Context, wg *sync.WaitGroup) {
	wg.Add(1)
	go func() {
		defer wg.Done()
		if err := kc.StartConsumerGroup(groupID, topics, ctx); err != nil {
			log.Printf("[%s] æ¶ˆè´¹è€…ç»„å¼‚å¸¸é€€å‡º: %v\n", groupID, err)
		}
	}()
}

func (kc *KafkaClient) ListConsumerGroups() error {
	admin, err := sarama.NewClusterAdmin(kc.brokers, kc.config)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºç®¡ç†å®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}
	defer admin.Close()

	groups, err := admin.ListConsumerGroups()
	if err != nil {
		return fmt.Errorf("è·å–æ¶ˆè´¹è€…ç»„å¤±è´¥: %w", err)
	}

	log.Printf("\n========== æ‰€æœ‰æ¶ˆè´¹è€…ç»„ ==========\n")
	if len(groups) == 0 {
		log.Println("å½“å‰æ²¡æœ‰ä»»ä½•æ¶ˆè´¹è€…ç»„")
	} else {
		for groupID, groupType := range groups {
			log.Printf("  - %s (ç±»å‹: %s)\n", groupID, groupType)
		}
	}
	log.Println("==================================")
	return nil
}

func (kc *KafkaClient) DescribeConsumerGroup(groupID string) error {
	admin, err := sarama.NewClusterAdmin(kc.brokers, kc.config)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºç®¡ç†å®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}
	defer admin.Close()

	groups, err := admin.DescribeConsumerGroups([]string{groupID})
	if err != nil {
		return fmt.Errorf("è·å–æ¶ˆè´¹è€…ç»„è¯¦æƒ…å¤±è´¥: %w", err)
	}

	log.Printf("\n========== æ¶ˆè´¹è€…ç»„ '%s' è¯¦æƒ… ==========\n", groupID)
	for _, group := range groups {
		log.Printf("çŠ¶æ€: %s\n", group.State)
		log.Printf("åè®®ç±»å‹: %s\n", group.ProtocolType)
		log.Printf("åè®®: %s\n", group.Protocol)
		log.Printf("æˆå‘˜æ•°: %d\n", len(group.Members))

		for memberID, member := range group.Members {
			log.Printf("\n  æˆå‘˜ ID: %s\n", memberID)
			log.Printf("    å®¢æˆ·ç«¯ ID: %s\n", member.ClientId)
			log.Printf("    å®¢æˆ·ç«¯ Host: %s\n", member.ClientHost)
		}
	}
	log.Println("==========================================")
	return nil
}

func main() {
	client := NewKafkaClient(
		[]string{"47.100.253.132:9092"},
		"admin",
		"QE5E3GrFDSCFRcsB",
	)

	producer, err := client.NewProducer()
	if err != nil {
		log.Fatalf("åˆ›å»ºç”Ÿäº§è€…å¤±è´¥: %v", err)
	}
	defer producer.Close()

	log.Println("\nå‘é€æ¶ˆæ¯...")
	for i := 1; i <= 10; i++ {
		key := fmt.Sprintf("user:%d", i)
		value := fmt.Sprintf(`{"id":%d,"msg":"hello from producer","timestamp":"%s"}`,
			i, time.Now().Format("2006-01-02 15:04:05"))

		if err := client.SendMessage(producer, "test-heiheihei", key, value); err != nil {
			log.Printf("#%d å¤±è´¥: %v\n", i, err)
		}
		time.Sleep(100 * time.Millisecond)
	}

	if err := client.ListAllTopics(); err != nil {
		log.Printf("%v\n", err)
	}

	time.Sleep(500 * time.Millisecond)
	if err := client.GetTopicInfo("test-heiheihei"); err != nil {
		log.Printf("%v\n", err)
	}

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	var wg sync.WaitGroup

	client.StartConsumerGroupAsync(
		"test-consumer-group-1",
		[]string{"test-heiheihei"},
		ctx,
		&wg,
	)

	client.StartConsumerGroupAsync(
		"test-consumer-group-2",
		[]string{"test-heiheihei"},
		ctx,
		&wg,
	)

	time.Sleep(5 * time.Second)

	if err := client.ListConsumerGroups(); err != nil {
		log.Printf("%v\n", err)
	}

	if err := client.DescribeConsumerGroup("test-consumer-group-1"); err != nil {
		log.Printf("%v\n", err)
	}

	log.Println("\nâ³ æ¶ˆè´¹è€…è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C é€€å‡º...")

	// ç›‘å¬ç³»ç»Ÿä¿¡å·
	sigterm := make(chan os.Signal, 1)
	signal.Notify(sigterm, syscall.SIGINT, syscall.SIGTERM)
	<-sigterm

	log.Println("\næ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
	cancel()
	wg.Wait()
	log.Println("æ‰€æœ‰æ¶ˆè´¹è€…å·²å…³é—­")
}
